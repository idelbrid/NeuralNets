{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 2\n",
    "M = [30, 35]\n",
    "N = [10, 15]\n",
    "batch_size = 35\n",
    "hidden_layer_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return 1 - ((np.round(y_pred) - y_true)**2).sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "synth_data = loadmat('./synth_dataset.mat')\n",
    "synth_data\n",
    "testX = synth_data['test_X'].reshape(-1, sum(m*n for m, n in zip(M, N)), 1)\n",
    "testY = np.ravel(synth_data['test_Y']).reshape(-1, 1)\n",
    "trainX = synth_data['train_X']\n",
    "trainY = np.ravel(synth_data['train_Y'])\n",
    "\n",
    "\n",
    "shuffle_idx = np.random.permutation(np.arange(len(trainX)))\n",
    "trainX = trainX[shuffle_idx]\n",
    "trainY = trainY[shuffle_idx]\n",
    "validX = trainX[:len(trainX)//4].reshape(-1, sum(m*n for m, n in zip(M, N)), 1)\n",
    "validY = trainY[:len(trainY)//4].reshape(-1, 1)\n",
    "trainX = trainX[len(trainX)//4:].reshape(-1, sum(m*n for m, n in zip(M, N)), 1)\n",
    "trainY = trainY[len(trainY)//4:].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, sum(m*n for m,n in zip(M, N)), 1))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "    tf_valid_dataset = tf.constant(validX, tf.float32)\n",
    "    tf_valid_labels = tf.constant(validY.reshape(-1,1), tf.float32)\n",
    "    tf_test_dataset = tf.constant(testX, tf.float32)\n",
    "    \n",
    "    layer0_weights = []\n",
    "    layer0_biases = []\n",
    "    for k in range(K):\n",
    "        kind_weights = tf.Variable(tf.truncated_normal([M[k], 1, hidden_layer_size], stddev=0.2))\n",
    "        layer0_weights.append(kind_weights)\n",
    "        \n",
    "        kind_biases = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "        layer0_biases.append(kind_biases)\n",
    "        \n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([sum(N[k]*hidden_layer_size for k in range(K)), 1], stddev=0.2)) \n",
    "    layer1_biases = tf.Variable(tf.zeros([1]))\n",
    "    \n",
    "    def model(data):\n",
    "        hidden_list = []\n",
    "        for k in range(K):\n",
    "            idx = sum(N[_k]*M[_k] for _k in range(0, k))\n",
    "            next_idx = N[k]*M[k] + idx\n",
    "            kind_conv = tf.nn.conv1d(data[:, idx:next_idx], layer0_weights[k], M[k], padding='VALID')\n",
    "            kind_hidden = kind_conv + layer0_biases[k]\n",
    "            hidden_list.append(kind_hidden)\n",
    "\n",
    "        hidden = tf.reshape(tf.concat(hidden_list, 1), (-1, sum(N[k]*hidden_layer_size for k in range(K))))\n",
    "        logits = tf.matmul( hidden, layer1_weights) + layer1_biases\n",
    "        return logits\n",
    "    \n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(.1).minimize(loss)\n",
    "    \n",
    "    train_prediction = tf.nn.sigmoid(logits)\n",
    "    valid_prediction = tf.nn.sigmoid(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.sigmoid(model(tf_test_dataset))\n",
    "    \n",
    "    train_accuracy = 1 - tf.reduce_mean(tf.square((tf.round(train_prediction) - tf_train_labels)))\n",
    "    valid_accuracy = 1 - tf.reduce_mean(tf.square((tf.round(valid_prediction) - tf_valid_labels)))\n",
    "#     test_accuracy = tf.reduce_sum(tf.square((tf.round(test_prediction) - tf)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 0: 1.757577\n",
      "Minibatch accuracy: 0.3%\n",
      "Validation accuracy: 0.5%\n",
      "Minibatch loss at step 200: 0.486929\n",
      "Minibatch accuracy: 0.7%\n",
      "Validation accuracy: 0.7%\n",
      "Minibatch loss at step 400: 0.341991\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.7%\n",
      "Minibatch loss at step 600: 0.357381\n",
      "Minibatch accuracy: 0.8%\n",
      "Validation accuracy: 0.7%\n",
      "Minibatch loss at step 800: 0.275935\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 1000: 0.299679\n",
      "Minibatch accuracy: 0.8%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 1200: 0.134272\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 1400: 0.212395\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 1600: 0.197030\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 1800: 0.199588\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 2000: 0.108071\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 2200: 0.468009\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 2400: 0.192525\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 2600: 0.071465\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 2800: 0.118670\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 3000: 0.465154\n",
      "Minibatch accuracy: 0.8%\n",
      "Validation accuracy: 0.7%\n",
      "Minibatch loss at step 3200: 0.064090\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 3400: 0.111194\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 3600: 0.082536\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 3800: 0.140035\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 4000: 0.056881\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 4200: 0.296678\n",
      "Minibatch accuracy: 0.9%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 4400: 0.107107\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 4600: 0.078263\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 4800: 0.025400\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 5000: 0.075378\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 5200: 0.067000\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 5400: 0.339305\n",
      "Minibatch accuracy: 0.8%\n",
      "Validation accuracy: 0.8%\n",
      "Minibatch loss at step 5600: 0.059528\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 5800: 0.036500\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 6000: 0.009987\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 0.9%\n",
      "Minibatch loss at step 6200: 0.040897\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 6400: 0.020338\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 6600: 0.007418\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 6800: 0.009274\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 7000: 0.006627\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 7200: 0.012092\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 7400: 0.002646\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 7600: 0.015075\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 7800: 0.021889\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 8000: 0.007769\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 8200: 0.005147\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 8400: 0.009080\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 8600: 0.004721\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 8800: 0.002127\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 9000: 0.004353\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 9200: 0.006454\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 9400: 0.003634\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 9600: 0.003353\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 9800: 0.003101\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 10000: 0.006785\n",
      "Minibatch accuracy: 1.0%\n",
      "Validation accuracy: 1.0%\n",
      "Test accuracy: 1.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (trainY.shape[0] - batch_size)\n",
    "        batch_data = trainX[offset:(offset+batch_size)]\n",
    "        batch_labels = trainY[offset:(offset+batch_size)]\n",
    "        feed_dict = {tf_train_dataset: batch_data, \n",
    "                     tf_train_labels: batch_labels}\n",
    "        _, l, batch_pred = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy(batch_labels, batch_pred))\n",
    "            print('Validation accuracy: %.1f%%' % valid_accuracy.eval())\n",
    "    print('Test accuracy: %.1f%%' % accuracy(testY,test_prediction.eval()))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
